# -*- coding: utf-8 -*-
"""AllenSDK_DataAnalysis001_SingleCellAnalysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1L8f3tsWY-ObxN97NdWQsVd_zIk3ros98

Installing the Allen SDK
"""

# # 1. Install a modern NumPy that works with Python 3.12
# !pip install "numpy>=1.26,<2.0"

# # 2. Install AllenSDK without trying to downgrade NumPy
# !pip install allensdk --no-deps

# # 3. Manually install its dependencies
# !pip install psycopg2-binary hdmf h5py matplotlib pandas requests scipy scikit-learn tqdm
# !pip install argschema boto3 glymur ndx-events pynrrd pynwb scikit-build semver SimpleITK

"""Imports and Verify that the SDK has been installed correctly"""

import allensdk
print("AllenSDK version:", allensdk.__version__)

# Try a common module
from allensdk.core.brain_observatory_cache import BrainObservatoryCache
import allensdk.brain_observatory.stimulus_info as stim_info
import pprint
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
print("BrainObservatoryCache loaded successfully!")
boc = BrainObservatoryCache(manifest_file='boc/manifest.json')

"""Getting the single cell data we want to explore and the inputs."""

# --- Inputs  ---
container_id = 	511510917     # replace with your experiment ID
cell_id = 517442396                # set to a specific cell ID or None for first cell
ori_choice = 60.0             # orientation of interest (deg)
sf_choice = 0.08              # spatial frequency
phase_choice = 0.5            # phase

# --- Get all experiments in that container ---
exps = boc.get_ophys_experiments(experiment_container_ids=[container_id])
print(f"Experiments in container {container_id}: {len(exps)}")
pprint.pprint(exps)

# --- Filter for the experiment with static gratings (Session B) ---
static_exp = boc.get_ophys_experiments(
    experiment_container_ids=[container_id],
    stimuli=[stim_info.STATIC_GRATINGS]
)[0]

exp_id = static_exp['id']
print(f"\nUsing Session B experiment with static gratings. Ophys experiment ID: {exp_id}")

# --- Load dataset ---
dataset = boc.get_ophys_experiment_data(exp_id)

"""Creating a table to use for analysis"""

# -----------------------------
# Load data
# -----------------------------

# Select cell
cell_ids = dataset.get_cell_specimen_ids()
if cell_id is None:
    cell_id = cell_ids[0]

times = dataset.get_fluorescence_timestamps()
_, dff_traces = dataset.get_dff_traces([cell_id])
trace = dff_traces[0]

# Stimulus table for static gratings
stim_table = dataset.get_stimulus_table("static_gratings")

# Filter for your chosen orientation, SF, and phase
subset = stim_table[
    (stim_table["orientation"] == ori_choice) &
    (stim_table["spatial_frequency"] == sf_choice) &
    (stim_table["phase"] == phase_choice)
]

print(f"Found {len(subset)} trials for ori={ori_choice}, sf={sf_choice}, phase={phase_choice}")

"""First, plot trial by trial for one specific stimulus (one specific phase, orientation, and phase)"""

#----------------------------
# Plot each trial separately
# --------------------------
for i, trial in subset.iterrows():
    stim_start_time = times[int(trial["start"])]
    stim_end_time   = times[int(trial["end"])]

    mask = (times >= stim_start_time) & (times <= stim_end_time)

    trial_time = times[mask] - stim_start_time   # reset to 0 at stimulus onset
    trial_trace = trace[mask]

    plt.figure(figsize=(8,4))
    plt.plot(trial_time, trial_trace, color="blue", label="dF/F")
    plt.axvspan(0, stim_end_time - stim_start_time, color="green", alpha=0.2, label="Stimulus ON")

    plt.xlabel("Time from stimulus onset (s)")
    plt.ylabel("dF/F")
    plt.title(f"Experiment {container_id} | Cell {cell_id}\n"
              f"Static Gratings | Trial {i}\n"
              f"Orientation={ori_choice}Â° | SF={sf_choice} | Phase={phase_choice}")
    plt.legend()
    plt.grid(True)
    plt.show()

"""Create a heatmap of all the trials, activity will be on the verical axis and time on the horizontal axis."""

# -----------------------------
# Build trial x time matrix with padding
# -----------------------------
all_trials = []

stim_durations = []  # store duration of each trial in frames

for i, trial in subset.iterrows():
    stim_start_time = times[int(trial["start"])]
    stim_end_time   = times[int(trial["end"])]
    mask = (times >= stim_start_time) & (times <= stim_end_time)

    trial_trace = trace[mask]
    all_trials.append(trial_trace)

    stim_durations.append(len(trial_trace))

# Pad trials to the max length
max_len = max([len(trial) for trial in all_trials])
trial_matrix = np.array([np.pad(trial, (0, max_len-len(trial)), constant_values=np.nan)
                         for trial in all_trials])

# Compute mean response ignoring NaNs
mean_response = np.nanmean(trial_matrix, axis=0)

# Time vector relative to stimulus onset
time_vector = np.arange(max_len) * np.mean(np.diff(times))  # assuming constant frame rate

# Plot the trial matrix as a heatmap
plt.figure(figsize=(10,6))
sns.heatmap(trial_matrix, cmap="viridis", cbar=True, xticklabels=False)
plt.xlabel("Time (s)")
plt.ylabel("Trial")
plt.title(f"Cell {cell_id} | Orientation {ori_choice}Â° | SF {sf_choice} | Phase {phase_choice}")
plt.show()

# Plot the average response with green shaded stimulus window
plt.figure(figsize=(8,4))
plt.plot(time_vector, mean_response, color="red", label="Mean dF/F")

# Add green shaded area for stimulus onset
stim_len = int(np.mean(stim_durations))  # approximate duration in frames
stim_time = stim_len * np.mean(np.diff(times))
plt.axvspan(0, stim_time, color="green", alpha=0.2, label="Stimulus ON")

plt.xlabel("Time from stimulus onset (s)")
plt.ylabel("Mean dF/F")
plt.title(f"Average response for Cell {cell_id}")
plt.legend()
plt.grid(True)
plt.show()

# -----------------------------
# Step: Response magnitude heatmap for all orientations x spatial frequencies
# -----------------------------

# Get all unique orientations and spatial frequencies
orientations = np.sort(stim_table["orientation"].unique())
sfs = np.sort(stim_table["spatial_frequency"].unique())

# Initialize matrix: rows = orientations, cols = spatial frequencies
response_matrix = np.zeros((len(orientations), len(sfs)))

# Loop over orientation and SF
for i, ori in enumerate(orientations):
    for j, sf in enumerate(sfs):
        # Filter trials for this stimulus combination
        subset_stim = stim_table[
            (stim_table["orientation"] == ori) &
            (stim_table["spatial_frequency"] == sf)
        ]

        if len(subset_stim) == 0:
            response_matrix[i, j] = np.nan  # no trials
            continue

        trial_responses = []
        for _, trial in subset_stim.iterrows():
            stim_start_time = times[int(trial["start"])]
            stim_end_time   = times[int(trial["end"])]
            mask = (times >= stim_start_time) & (times <= stim_end_time)
            trial_trace = trace[mask]

            # Baseline: use 1s before stimulus onset if available
            baseline_mask = (times >= stim_start_time - 1) & (times < stim_start_time)
            baseline = np.mean(trace[baseline_mask]) if np.any(baseline_mask) else 0

            # Response magnitude = mean dF/F during stimulus - baseline
            response_mag = np.mean(trial_trace) - baseline
            trial_responses.append(response_mag)

        # Average across trials for this stimulus
        response_matrix[i, j] = np.mean(trial_responses)

# -----------------------------
# Plot the response magnitude heatmap
# -----------------------------
plt.figure(figsize=(8,6))
sns.heatmap(response_matrix, cmap="viridis", xticklabels=np.round(sfs,3),
            yticklabels=np.round(orientations,1), cbar_kws={'label': 'Response magnitude'})
plt.xlabel("Spatial Frequency (cyc/deg)")
plt.ylabel("Orientation (deg)")
plt.title(f"Cell {cell_id} | Response magnitude heatmap")
plt.show()

"""Sanity check for Cell 51442396 in experiment 511510917. Sanity check worked out since highest response magnitude was as expected."""

from mpl_toolkits.mplot3d import Axes3D

# -----------------------------
# Build response magnitude matrix across all cells, orientations, SF
# -----------------------------

# Use all cells from the experiment
cell_ids = dataset.get_cell_specimen_ids()

# Optionally map cells to their structures for nicer labels
cell_metadata = pd.DataFrame(boc.get_cell_specimens())
cell_metadata = cell_metadata[cell_metadata["cell_specimen_id"].isin(cell_ids)]

# Map targeted_structure from container metadata
containers = pd.DataFrame(boc.get_experiment_containers())
cell_metadata = cell_metadata.merge(
    containers[["id", "targeted_structure"]],
    left_on="experiment_container_id",
    right_on="id",
    how="left"
).drop(columns="id")

# Create labels like VISp-517442396
cell_metadata["label"] = cell_metadata["targeted_structure"].fillna("NA") + "-" + cell_metadata["cell_specimen_id"].astype(str)

# Sort cells so layers are grouped by area
cell_metadata = cell_metadata.sort_values(["targeted_structure", "cell_specimen_id"])
sorted_cell_ids = cell_metadata["cell_specimen_id"].tolist()
sorted_labels = cell_metadata["label"].tolist()

# Stimulus conditions
orientations = np.sort(stim_table["orientation"].dropna().unique())
sfs = np.sort(stim_table["spatial_frequency"].dropna().unique())

# Collect points for plotting
X, Y, Z, C = [], [], [], []

for k, cid in enumerate(sorted_cell_ids):   # z-axis = cell index
    _, dff_traces = dataset.get_dff_traces([cid])
    trace = dff_traces[0]

    for i, ori in enumerate(orientations):
        for j, sf in enumerate(sfs):
            subset_stim = stim_table[
                (stim_table["orientation"] == ori) &
                (stim_table["spatial_frequency"] == sf)
            ]

            if len(subset_stim) == 0:
                continue

            trial_responses = []
            for _, trial in subset_stim.iterrows():
                stim_start_time = times[int(trial["start"])]
                stim_end_time   = times[int(trial["end"])]
                mask = (times >= stim_start_time) & (times <= stim_end_time)
                trial_trace = trace[mask]

                # Baseline = 1s before onset if available
                baseline_mask = (times >= stim_start_time - 1) & (times < stim_start_time)
                baseline = np.mean(trace[baseline_mask]) if np.any(baseline_mask) else 0

                response_mag = np.mean(trial_trace) - baseline
                trial_responses.append(response_mag)

            # Average across trials for this condition
            mean_resp = np.mean(trial_responses)

            # Add to arrays
            X.append(i)         # orientation index
            Y.append(j)         # spatial frequency index
            Z.append(k)         # cell layer
            C.append(mean_resp)

from mpl_toolkits.mplot3d import Axes3D
import matplotlib.cm as cm

fig = plt.figure(figsize=(12,8))
ax = fig.add_subplot(111, projection="3d")

# Choose a small subset of cells (to avoid overload in 3D)
for k, (cid, label) in enumerate(zip(sorted_cell_ids[:10], sorted_labels[:10])):
    _, dff_traces = dataset.get_dff_traces([cid])
    trace = dff_traces[0]

    # Build response matrix
    response_matrix = np.zeros((len(orientations), len(sfs)))
    for i, ori in enumerate(orientations):
        for j, sf in enumerate(sfs):
            subset_stim = stim_table[
                (stim_table["orientation"] == ori) &
                (stim_table["spatial_frequency"] == sf)
            ]
            if len(subset_stim) == 0:
                response_matrix[i, j] = np.nan
                continue
            trial_responses = []
            for _, trial in subset_stim.iterrows():
                stim_start = times[int(trial["start"])]
                stim_end   = times[int(trial["end"])]
                mask = (times >= stim_start) & (times <= stim_end)
                trial_trace = trace[mask]
                baseline_mask = (times >= stim_start-1) & (times < stim_start)
                baseline = np.mean(trace[baseline_mask]) if np.any(baseline_mask) else 0
                trial_responses.append(np.mean(trial_trace)-baseline)
            response_matrix[i, j] = np.mean(trial_responses)

    # Flatten the matrix and scatter as points
    X, Y = np.meshgrid(range(len(sfs)), range(len(orientations)))
    Z = np.full_like(X, k)

    values = response_matrix.flatten()
    sc = ax.scatter(
        X.flatten(), Y.flatten(), Z.flatten(),
        c=values, cmap="viridis", s=60, edgecolor="k"
    )

# Axis labels and ticks
ax.set_xticks(range(len(sfs)))
ax.set_xticklabels([f"{sf:.2f}" for sf in sfs])
ax.set_xlabel("Spatial Frequency")

ax.set_yticks(range(len(orientations)))
ax.set_yticklabels([f"{o:.0f}" for o in orientations])
ax.set_ylabel("Orientation (deg)")

ax.set_zticks(range(len(sorted_cell_ids[:10])))
ax.set_zticklabels(sorted_labels[:10])
ax.set_zlabel("Cells")

plt.title("3D dot plot of response magnitude\n(orientation Ã SF Ã cell)")
fig.colorbar(sc, ax=ax, shrink=0.5, label="Response magnitude")
plt.show()

#Using this function to see what other data is avaliable
dir(dataset)
